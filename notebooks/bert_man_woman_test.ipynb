{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.manual_seed(17)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\", use_fast=True, \n",
    "                                          add_prefix_space=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"prajjwal1/bert-small\", return_dict_in_generate=True, \n",
    "                                             pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"astro ##physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(model(torch.tensor([[101]])).logits, dim=-1).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([2028])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([15638])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path.append(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_relm_resources.automata_examples.man_woman_wfa import get_man_woman_wfa\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "\n",
    "property_model = get_man_woman_wfa(SymbolStr(tokenizer.sep_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.bert_small.bert_small_probabilistic_model_wrapper import BERT_SMALL_probabilistic_model_wrapper\n",
    "from mini_relm_resources.automata_examples.man_woman_wfa import alphabet\n",
    "\n",
    "wrapper = BERT_SMALL_probabilistic_model_wrapper(alphabet, device, model, tokenizer, property_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.sequence import Sequence\n",
    "wrapper.get_last_token_weights(Sequence([SymbolStr('The')]), [\"man\", \"woman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.sequence import Sequence\n",
    "from pythautomata.utilities.sequence_generator import SequenceGenerator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GuidedSequenceGenerator(SequenceGenerator):    \n",
    "    def __init__(self, guide, max_seq_length: int, random_seed: int = 21):\n",
    "        self.guide = guide\n",
    "        super().__init__(guide.alphabet, max_seq_length, random_seed)\n",
    "    \n",
    "    def generate_words(self, number_of_words: int):\n",
    "        return [self.generate_single_word(0) for _ in range(number_of_words)]\n",
    "\n",
    "    def generate_single_word(self, length):\n",
    "        word = Sequence()\n",
    "        first_state = list(filter(lambda x: x.initial_weight ==\n",
    "                        1, self.guide.weighted_states))[0]\n",
    "        symbols, weights, next_states = first_state.get_all_symbol_weights()\n",
    "        next_symbol = np.random.choice(symbols, p=weights)\n",
    "        while next_symbol != self.guide.terminal_symbol:\n",
    "            word += next_symbol\n",
    "            i = symbols.index(next_symbol)\n",
    "            next_state = next_states[i]\n",
    "            symbols, weights, next_states = next_state.get_all_symbol_weights()\n",
    "            weights = np.array(weights)\n",
    "            weights = weights / sum(weights)\n",
    "            next_symbol = np.random.choice(symbols, p=weights)\n",
    "        return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(property_model)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.syncronic_model_guided_language_model import SyncronicModelGuidedLanguageModel\n",
    "synchronic_model = SyncronicModelGuidedLanguageModel(wrapper, property_model, model_name=\"GUIDED_BERT_SMALL\", max_seq_length=10, normalize_outputs=True, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_probabilistic_teacher import PACProbabilisticTeacher\n",
    "from pymodelextractor.learners.observation_tree_learners.bounded_pdfa_quantization_n_ary_tree_learner import BoundedPDFAQuantizationNAryTreeLearner\n",
    "from pythautomata.utilities.probability_partitioner import TopKProbabilityPartitioner, QuantizationProbabilityPartitioner, RankingPartitioner\n",
    "from pythautomata.model_comparators.wfa_partition_comparison_strategy import WFAPartitionComparator\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "\n",
    "partitioner = QuantizationProbabilityPartitioner(100)\n",
    "comparator = WFAPartitionComparator(partitioner)\n",
    "epsilon = 0.1\n",
    "delta = epsilon\n",
    "sequence_generator = GuidedSequenceGenerator(property_model, max_seq_length=10)\n",
    "max_states = 10\n",
    "max_query_length = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher  = PACProbabilisticTeacher(synchronic_model, epsilon = epsilon, delta = delta, max_seq_length = None, comparator = comparator, sequence_generator=sequence_generator, compute_epsilon_star=False)\n",
    "learner = BoundedPDFAQuantizationNAryTreeLearner(partitioner, max_states, max_query_length, None, generate_partial_hipothesis = True, pre_cache_queries_for_building_hipothesis = True,  check_probabilistic_hipothesis = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_result = learner.learn(teacher, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = exporter.create_graph(learning_result.model)\n",
    "\n",
    "display(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
