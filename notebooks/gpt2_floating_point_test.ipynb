{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the LLM, in this case we are using gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=True, local_files_only = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                            return_dict_in_generate=True,\n",
    "                                            pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.gpt2.gpt2_probabilistic_model_wrapper import GPT2_probabilistic_model_wrapper\n",
    "from mini_relm_resources.automata_examples.floating_point_wfa import alphabet\n",
    "\n",
    "wrapper = GPT2_probabilistic_model_wrapper(50, alphabet, device, model, tokenizer)\n",
    "#from utilities.mock_probabilistic_model import MockProbabilisticModel\n",
    "#from pythautomata.base_types.symbol import SymbolStr\n",
    "#terminal_symbol = SymbolStr(tokenizer.eos_token)\n",
    "#wrapper = MockProbabilisticModel(alphabet, terminal_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_relm_resources.automata_examples.floating_point_wfa import get_floating_point_wfa\n",
    "guiding_wfa = get_floating_point_wfa(wrapper.terminal_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.guiding_wfa_sequence_generator import GuidingWDFASequenceGenerator\n",
    "guiding_generator = GuidingWDFASequenceGenerator(guiding_wfa, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ϵ,\n",
       " .,9,1,\n",
       " 6,2,6,7,5,6,1,\n",
       " 7,\n",
       " ϵ,\n",
       " 8,9,9,\n",
       " .,5,9,3,\n",
       " ϵ,\n",
       " 6,.,\n",
       " .,6,2,9,\n",
       " 8,3,3,\n",
       " ϵ,\n",
       " 7,\n",
       " 4,0,2,5,2,\n",
       " 0,.,7,\n",
       " 5,5,6,7,8,2,0,2,0,5,9,.,2,\n",
       " ϵ,\n",
       " ϵ,\n",
       " ϵ,\n",
       " 2,\n",
       " ϵ,\n",
       " 4,5,3,2,\n",
       " 8,9,\n",
       " 0,1,9,\n",
       " 4,9,0,2,4,8,9,\n",
       " 8,5,4,9,8,\n",
       " 5,5,\n",
       " 6,\n",
       " ϵ,\n",
       " ϵ,\n",
       " 7,0,\n",
       " 8,6,\n",
       " ϵ,\n",
       " 0,\n",
       " 6,7,6,7,.,\n",
       " 7,9,7,9,9,.,7,6,6,0,\n",
       " 6,1,1,9,\n",
       " 1,2,3,5,.,\n",
       " ϵ,\n",
       " ϵ,\n",
       " 2,8,\n",
       " 4,2,7,7,4,.,4,\n",
       " 3,\n",
       " 5,\n",
       " 0,7,3,8,\n",
       " 3,0,2,6,0,6,8,9,9,0,1,\n",
       " .,\n",
       " ϵ,\n",
       " 9,7,.,4,\n",
       " .,1,2,\n",
       " 5,0,\n",
       " 4,.,0,\n",
       " 8,3,\n",
       " 6,\n",
       " 3,\n",
       " 8,.,\n",
       " 7,7,4,3,.,8,1,6,7,5,\n",
       " 9,0,.,2,8,6,8,7,5,3,2,\n",
       " 5,0,9,.,1,8,8,2,6,7,3,4,\n",
       " 3,4,\n",
       " 3,\n",
       " 9,4,\n",
       " 2,6,\n",
       " 9,7,\n",
       " 8,7,0,2,7,9,9,1,1,4,7,3,5,1,3,2,4,\n",
       " .,3,\n",
       " 7,.,8,3,4,\n",
       " 6,\n",
       " 9,0,3,7,8,5,0,5,\n",
       " 7,7,9,3,\n",
       " 7,9,\n",
       " ϵ,\n",
       " 2,\n",
       " 5,0,3,\n",
       " 2,1,\n",
       " .,1,3,1,3,1,6,8,0,5,\n",
       " 6,\n",
       " 6,9,0,1,4,\n",
       " 2,5,.,4,\n",
       " 1,2,2,6,\n",
       " 7,0,6,1,7,5,0,4,6,\n",
       " 6,2,\n",
       " 5,\n",
       " .,3,8,3,9,2,7,\n",
       " .,\n",
       " .,1,3,4,6,2,0,4,3,9,3,0,6,7,\n",
       " 2,6,4,8,2,1,\n",
       " ϵ,\n",
       " 1,1,\n",
       " .,4,6,8,\n",
       " 6,4,5,4,2,.,5,2,4,2,\n",
       " 2,\n",
       " 0,\n",
       " ϵ,\n",
       " .,2,9,9,1,\n",
       " 6,3,6,4,\n",
       " ϵ,\n",
       " 3,6,3,1,7,\n",
       " 2,\n",
       " 0,7]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guiding_generator.generate_words(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"851pt\" height=\"572pt\"\n",
       " viewBox=\"0.00 0.00 851.11 572.47\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 568.47)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-568.47 847.11,-568.47 847.11,4 -4,4\"/>\n",
       "<!-- dot -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>dot</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"379.43\" cy=\"-230.25\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.43\" y=\"-232.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dot</text>\n",
       "<text text-anchor=\"middle\" x=\"379.43\" y=\"-216.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- more_numbers -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>more_numbers</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.11\" cy=\"-318.25\" rx=\"70.71\" ry=\"70.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-320.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">more_numbers</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-304.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- dot&#45;&gt;more_numbers -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>dot&#45;&gt;more_numbers</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M404.19,-243.43C421.13,-252.83 444.88,-265.99 467.73,-278.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.03,-281.73 476.47,-283.51 469.42,-275.6 466.03,-281.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-408.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-392.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-376.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-361.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-345.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-329.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-313.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-298.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-282.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"434.36\" y=\"-266.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;1</text>\n",
       "</g>\n",
       "<!-- hole -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>hole</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"756.49\" cy=\"-230.25\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-232.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hole</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-216.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- dot&#45;&gt;hole -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>dot&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M407.36,-227.03C423.08,-225.3 443.32,-223.37 461.36,-222.5 553.06,-218.12 660.96,-223.71 717.13,-227.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"716.58,-230.9 726.79,-228.09 717.05,-223.92 716.58,-230.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-225.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;0</text>\n",
       "</g>\n",
       "<!-- more_numbers&#45;&gt;more_numbers -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>more_numbers&#45;&gt;more_numbers</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M521.86,-387.07C524.36,-398.82 530.44,-406.97 540.11,-406.97 546.46,-406.97 551.26,-403.46 554.52,-397.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"557.75,-399.08 557.85,-388.49 551.16,-396.71 557.75,-399.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-551.17\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-535.42\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-519.67\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-503.92\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-488.17\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-472.42\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-456.67\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-440.92\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-425.17\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"540.11\" y=\"-409.42\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;1</text>\n",
       "</g>\n",
       "<!-- more_numbers&#45;&gt;hole -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>more_numbers&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M606.01,-291.61C643.38,-276.27 688.92,-257.58 719.84,-244.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"720.81,-248.27 728.73,-241.24 718.15,-241.8 720.81,-248.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"644.36\" y=\"-279.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;0</text>\n",
       "</g>\n",
       "<!-- hole&#45;&gt;hole -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>hole&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737.13,-250.56C732.08,-263.62 738.53,-276.19 756.49,-276.19 769.11,-276.19 776.05,-269.97 777.3,-261.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"780.8,-261.53 776.04,-252.06 773.86,-262.43 780.8,-261.53\"/>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-436.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-420.39\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-404.64\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-388.89\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-373.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-357.39\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-341.64\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-325.89\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-310.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-294.39\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"756.49\" y=\"-278.64\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;0</text>\n",
       "</g>\n",
       "<!-- initial -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>initial</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-212.75 0,-173.25 44.5,-133.75 89,-173.25 44.5,-212.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"44.5\" y=\"-175.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">initial</text>\n",
       "<text text-anchor=\"middle\" x=\"44.5\" y=\"-159.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- initial&#45;&gt;dot -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>initial&#45;&gt;dot</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.01,-205.74C61.23,-233.1 77.38,-270.51 107,-288.25 121.16,-296.74 60.27,-349.25 300.5,-275.25 316.84,-270.22 333.45,-261.27 347.12,-252.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"348.78,-255.76 355.23,-247.35 344.95,-249.9 348.78,-255.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-316.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;1</text>\n",
       "</g>\n",
       "<!-- numbers -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>numbers</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"221.75\" cy=\"-45.25\" rx=\"45.25\" ry=\"45.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-47.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">numbers</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-31.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- initial&#45;&gt;numbers -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>initial&#45;&gt;numbers</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.5,-155.73C96.66,-135.89 141.52,-103.12 175.35,-78.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"177.34,-81.29 183.35,-72.57 173.21,-75.64 177.34,-81.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-272.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-256.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-240.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-225.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-209.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-193.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-177.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-162.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-146.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-130.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;1</text>\n",
       "</g>\n",
       "<!-- numbers&#45;&gt;dot -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>numbers&#45;&gt;dot</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.67,-79.62C280.84,-114.29 325.44,-167.29 353.22,-200.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.49,-202.49 359.61,-207.89 355.85,-197.98 350.49,-202.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"326\" y=\"-178.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;1</text>\n",
       "</g>\n",
       "<!-- numbers&#45;&gt;numbers -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>numbers&#45;&gt;numbers</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.25,-86.62C202.83,-98.93 209.33,-108.51 221.75,-108.51 230.09,-108.51 235.77,-104.19 238.77,-97.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242.13,-98.63 240.92,-88.1 235.3,-97.08 242.13,-98.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-252.71\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-236.96\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-221.21\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-205.46\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-189.71\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-173.96\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-158.21\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-142.46\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-126.71\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.75\" y=\"-110.96\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;1</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x119b4cbe820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(guiding_wfa)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.syncronic_model_guided_language_model import SyncronicModelGuidedLanguageModel\n",
    "syncrhronic_model = SyncronicModelGuidedLanguageModel(wrapper, guiding_wfa, model_name=\"GUIDED_GPT2\", max_seq_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_probabilistic_teacher import PACProbabilisticTeacher\n",
    "from pymodelextractor.learners.observation_tree_learners.bounded_pdfa_quantization_n_ary_tree_learner import BoundedPDFAQuantizationNAryTreeLearner\n",
    "#from pythautomata.utilities.probability_partitioner import TopKProbabilityPartitioner, QuantizationProbabilityPartitioner, RankingPartitioner\n",
    "from utilities.floating_point_partitioner import FloatingPointProbabilityPartitioner\n",
    "from pythautomata.model_comparators.wfa_partition_comparison_strategy import WFAPartitionComparator\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "partitioner = FloatingPointProbabilityPartitioner()\n",
    "comparator = WFAPartitionComparator(partitioner)\n",
    "epsilon = 0.05\n",
    "delta = epsilon\n",
    "sequence_generator = guiding_generator\n",
    "max_states = 30\n",
    "max_query_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher  = PACProbabilisticTeacher(syncrhronic_model, epsilon = epsilon, delta = delta, max_seq_length = None, comparator = comparator, sequence_generator=guiding_generator, compute_epsilon_star=False)\n",
    "learner = BoundedPDFAQuantizationNAryTreeLearner(partitioner, max_states, max_query_length, None, generate_partial_hipothesis = True, pre_cache_queries_for_building_hipothesis = True,  check_probabilistic_hipothesis = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_result = learner.learn(teacher, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.sequence import Sequence\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "test_seq = Sequence([SymbolStr(\".\"),SymbolStr(\".\")])\n",
    "#teacher.next_token_probabilities(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def next_token_probabilities(model, sequence):\n",
    "        symbols = list(model.alphabet.symbols)\n",
    "        symbols.sort()\n",
    "        symbols = [model.terminal_symbol] + symbols\n",
    "        probabilities = model.get_last_token_weights(sequence, symbols)\n",
    "        probabilities = OrderedDict(zip(symbols, probabilities))\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.uniform_length_sequence_generator import UniformLengthSequenceGenerator\n",
    "generator = UniformLengthSequenceGenerator(alphabet, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ϵ [1]\n",
      ". [1]\n",
      "0 [0]\n",
      "1 [0]\n",
      "2 [0]\n",
      "3 [0]\n",
      "4 [0]\n",
      "5 [0]\n",
      "6 [0]\n",
      "7 [0]\n",
      "8 [0]\n",
      "9 [0]\n",
      ".,. [2]\n",
      ".,0 [0]\n",
      ".,1 [0]\n",
      ".,2 [0]\n",
      ".,3 [0]\n",
      ".,4 [0]\n",
      ".,5 [0]\n",
      ".,6 [0]\n",
      ".,7 [0]\n",
      ".,8 [0]\n",
      ".,9 [0]\n",
      "0,. [1]\n",
      "0,0 [0]\n",
      "0,1 [0]\n",
      "0,2 [0]\n",
      "0,3 [0]\n",
      "0,4 [0]\n",
      "0,5 [0]\n",
      "0,6 [0]\n",
      "0,7 [0]\n",
      "0,8 [0]\n",
      "0,9 [0]\n",
      "1,. [1]\n",
      "1,0 [0]\n",
      "1,1 [0]\n",
      "1,2 [0]\n",
      "1,3 [0]\n",
      "1,4 [0]\n",
      "1,5 [0]\n",
      "1,6 [0]\n",
      "1,7 [0]\n",
      "1,8 [0]\n",
      "1,9 [0]\n",
      "2,. [1]\n",
      "2,0 [0]\n",
      "2,1 [0]\n",
      "2,2 [0]\n",
      "2,3 [0]\n",
      "2,4 [0]\n",
      "2,5 [0]\n",
      "2,6 [0]\n",
      "2,7 [0]\n",
      "2,8 [0]\n",
      "2,9 [0]\n",
      "3,. [1]\n",
      "3,0 [0]\n",
      "3,1 [0]\n",
      "3,2 [0]\n",
      "3,3 [0]\n",
      "3,4 [0]\n",
      "3,5 [0]\n",
      "3,6 [0]\n",
      "3,7 [0]\n",
      "3,8 [0]\n",
      "3,9 [0]\n",
      "4,. [1]\n",
      "4,0 [0]\n",
      "4,1 [0]\n",
      "4,2 [0]\n",
      "4,3 [0]\n",
      "4,4 [0]\n",
      "4,5 [0]\n",
      "4,6 [0]\n",
      "4,7 [0]\n",
      "4,8 [0]\n",
      "4,9 [0]\n",
      "5,. [1]\n",
      "5,0 [0]\n",
      "5,1 [0]\n",
      "5,2 [0]\n",
      "5,3 [0]\n",
      "5,4 [0]\n",
      "5,5 [0]\n",
      "5,6 [0]\n",
      "5,7 [0]\n",
      "5,8 [0]\n",
      "5,9 [0]\n",
      "6,. [1]\n",
      "6,0 [0]\n",
      "6,1 [0]\n",
      "6,2 [0]\n",
      "6,3 [0]\n",
      "6,4 [0]\n",
      "6,5 [0]\n",
      "6,6 [0]\n",
      "6,7 [0]\n",
      "6,8 [0]\n",
      "6,9 [0]\n",
      "7,. [1]\n",
      "7,0 [0]\n",
      "7,1 [0]\n",
      "7,2 [0]\n",
      "7,3 [0]\n",
      "7,4 [0]\n",
      "7,5 [0]\n",
      "7,6 [0]\n",
      "7,7 [0]\n",
      "7,8 [0]\n",
      "7,9 [0]\n",
      "8,. [1]\n",
      "8,0 [0]\n",
      "8,1 [0]\n",
      "8,2 [0]\n",
      "8,3 [0]\n",
      "8,4 [0]\n",
      "8,5 [0]\n",
      "8,6 [0]\n",
      "8,7 [0]\n",
      "8,8 [0]\n",
      "8,9 [0]\n",
      "9,. [1]\n",
      "9,0 [0]\n",
      "9,1 [0]\n",
      "9,2 [0]\n",
      "9,3 [0]\n",
      "9,4 [0]\n",
      "9,5 [0]\n",
      "9,6 [0]\n",
      "9,7 [0]\n",
      "9,8 [0]\n",
      "9,9 [0]\n",
      ".,.,. [2]\n",
      ".,.,0 [2]\n",
      ".,.,1 [2]\n",
      ".,.,2 [2]\n",
      ".,.,3 [2]\n",
      ".,.,4 [2]\n",
      ".,.,5 [2]\n",
      ".,.,6 [2]\n",
      ".,.,7 [2]\n",
      ".,.,8 [2]\n",
      ".,.,9 [2]\n",
      ".,0,. [2]\n",
      ".,0,0 [0]\n",
      ".,0,1 [0]\n",
      ".,0,2 [0]\n",
      ".,0,3 [0]\n",
      ".,0,4 [0]\n",
      ".,0,5 [0]\n",
      ".,0,6 [0]\n",
      ".,0,7 [0]\n",
      ".,0,8 [0]\n",
      ".,0,9 [0]\n",
      ".,1,. [2]\n",
      ".,1,0 [0]\n",
      ".,1,1 [0]\n",
      ".,1,2 [0]\n",
      ".,1,3 [0]\n",
      ".,1,4 [0]\n",
      ".,1,5 [0]\n",
      ".,1,6 [0]\n",
      ".,1,7 [0]\n",
      ".,1,8 [0]\n",
      ".,1,9 [0]\n",
      ".,2,. [2]\n",
      ".,2,0 [0]\n",
      ".,2,1 [0]\n",
      ".,2,2 [0]\n",
      ".,2,3 [0]\n",
      ".,2,4 [0]\n",
      ".,2,5 [0]\n",
      ".,2,6 [0]\n",
      ".,2,7 [0]\n",
      ".,2,8 [0]\n",
      ".,2,9 [0]\n",
      ".,3,. [2]\n",
      ".,3,0 [0]\n",
      ".,3,1 [0]\n",
      ".,3,2 [0]\n",
      ".,3,3 [0]\n",
      ".,3,4 [0]\n",
      ".,3,5 [0]\n",
      ".,3,6 [0]\n",
      ".,3,7 [0]\n",
      ".,3,8 [0]\n",
      ".,3,9 [0]\n",
      ".,4,. [2]\n",
      ".,4,0 [0]\n",
      ".,4,1 [0]\n",
      ".,4,2 [0]\n",
      ".,4,3 [0]\n",
      ".,4,4 [0]\n",
      ".,4,5 [0]\n",
      ".,4,6 [0]\n",
      ".,4,7 [0]\n",
      ".,4,8 [0]\n",
      ".,4,9 [0]\n",
      ".,5,. [2]\n",
      ".,5,0 [0]\n",
      ".,5,1 [0]\n",
      ".,5,2 [0]\n",
      ".,5,3 [0]\n",
      ".,5,4 [0]\n",
      ".,5,5 [0]\n",
      ".,5,6 [0]\n",
      ".,5,7 [0]\n",
      ".,5,8 [0]\n",
      ".,5,9 [0]\n",
      ".,6,. [2]\n",
      ".,6,0 [0]\n",
      ".,6,1 [0]\n",
      ".,6,2 [0]\n",
      ".,6,3 [0]\n",
      ".,6,4 [0]\n",
      ".,6,5 [0]\n",
      ".,6,6 [0]\n",
      ".,6,7 [0]\n",
      ".,6,8 [0]\n",
      ".,6,9 [0]\n",
      ".,7,. [2]\n",
      ".,7,0 [0]\n",
      ".,7,1 [0]\n",
      ".,7,2 [0]\n",
      ".,7,3 [0]\n",
      ".,7,4 [0]\n",
      ".,7,5 [0]\n",
      ".,7,6 [0]\n",
      ".,7,7 [0]\n",
      ".,7,8 [0]\n",
      ".,7,9 [0]\n",
      ".,8,. [2]\n",
      ".,8,0 [0]\n",
      ".,8,1 [0]\n",
      ".,8,2 [0]\n",
      ".,8,3 [0]\n",
      ".,8,4 [0]\n",
      ".,8,5 [0]\n",
      ".,8,6 [0]\n",
      ".,8,7 [0]\n",
      ".,8,8 [0]\n",
      ".,8,9 [0]\n",
      ".,9,. [2]\n",
      ".,9,0 [0]\n",
      ".,9,1 [0]\n",
      ".,9,2 [0]\n",
      ".,9,3 [0]\n",
      ".,9,4 [0]\n",
      ".,9,5 [0]\n",
      ".,9,6 [0]\n",
      ".,9,7 [0]\n",
      ".,9,8 [0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m words \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgenerate_all_words()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m----> 5\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnext_token_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msyncrhronic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m      6\u001b[0m     part \u001b[38;5;241m=\u001b[39m partitioner\u001b[38;5;241m.\u001b[39mget_partition(probs)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(word, part)\n",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m, in \u001b[0;36mnext_token_probabilities\u001b[1;34m(model, sequence)\u001b[0m\n\u001b[0;32m      4\u001b[0m symbols\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m      5\u001b[0m symbols \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mterminal_symbol] \u001b[38;5;241m+\u001b[39m symbols\n\u001b[1;32m----> 6\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[38;5;28mzip\u001b[39m(symbols, probabilities))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\utilities\\syncronic_model_guided_language_model.py:113\u001b[0m, in \u001b[0;36mSyncronicModelGuidedLanguageModel.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m    111\u001b[0m guiding_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guiding_model\u001b[38;5;241m.\u001b[39mget_last_token_weights(sequence, required_suffixes)\n\u001b[0;32m    112\u001b[0m required_suffixes \u001b[38;5;241m=\u001b[39m [required_suffixes[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(required_suffixes)) \u001b[38;5;28;01mif\u001b[39;00m guiding_results[i]]\n\u001b[1;32m--> 113\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m model_results_full \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    115\u001b[0m j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:49\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m     46\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#alphabet_symbols_weights = self.next_symbol_probas(sequence)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#alphabet_symbols_weights = {Sequence() + k: alphabet_symbols_weights[k] for k in alphabet_symbols_weights.keys()}\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m alphabet_symbols_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_token_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m required_suffixes:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m alphabet_symbols_weights:\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:42\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.last_token_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     40\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alphabet\u001b[38;5;241m.\u001b[39msymbols)\n\u001b[0;32m     41\u001b[0m     symbols\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_symbol)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:83\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     80\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_ids_sequence_from_tokens(str_seq)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 83\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# logits = output[0]\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# probs = logits.softmax(-1)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    878\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    885\u001b[0m         output_attentions,\n\u001b[0;32m    886\u001b[0m     )\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:426\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    423\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attn_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m    425\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 426\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m(hidden_states)\n\u001b[0;32m    427\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "res = list()\n",
    "words = generator.generate_all_words()\n",
    "for word in words:\n",
    "    probs = list(next_token_probabilities(syncrhronic_model, word).values())\n",
    "    part = partitioner.get_partition(probs)\n",
    "    print(word, part)\n",
    "    #if np.sum(probs) > 0:\n",
    "    #    print(word, part)\n",
    "    #    res.append((word, probs))\n",
    "    #if len(res)>1000:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, tensor(0.0019)),\n",
       "             (., tensor(0.8010)),\n",
       "             (0, tensor(0.0005)),\n",
       "             (1, tensor(0.0011)),\n",
       "             (2, tensor(0.0006)),\n",
       "             (3, tensor(0.0004)),\n",
       "             (4, tensor(0.0006)),\n",
       "             (5, tensor(0.0005)),\n",
       "             (6, tensor(0.0005)),\n",
       "             (7, tensor(0.0004)),\n",
       "             (8, tensor(0.0004)),\n",
       "             (9, tensor(0.0003))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(wrapper, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, 0),\n",
       "             (., 0),\n",
       "             (0, 0),\n",
       "             (1, 0),\n",
       "             (2, 0),\n",
       "             (3, 0),\n",
       "             (4, 0),\n",
       "             (5, 0),\n",
       "             (6, 0),\n",
       "             (7, 0),\n",
       "             (8, 0),\n",
       "             (9, 0)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(guiding_wfa, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, 0),\n",
       "             (., 0),\n",
       "             (0, 0),\n",
       "             (1, 0),\n",
       "             (2, 0),\n",
       "             (3, 0),\n",
       "             (4, 0),\n",
       "             (5, 0),\n",
       "             (6, 0),\n",
       "             (7, 0),\n",
       "             (8, 0),\n",
       "             (9, 0)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(syncrhronic_model, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"526pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 526.35 407.33\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 403.33)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-403.33 522.35,-403.33 522.35,4 -4,4\"/>\n",
       "<!-- 6 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"109.42\" cy=\"-114.41\" rx=\"109.42\" ry=\"109.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-116.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-101.11\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0004006822418887168</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;6 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>6&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.4,-218.89C81.2,-232.68 92.54,-241.83 109.42,-241.83 121.82,-241.83 131.23,-236.9 137.66,-228.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.67,-230.6 142.69,-220.2 134.62,-227.07 140.67,-230.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-386.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;0.0006370311020873487</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-370.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;0.002243992406874895</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-354.53\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;0.00130686373449862</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-338.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;0.0014230640372261405</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-323.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;0.0009345221915282309</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-307.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;0.0010465433588251472</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-291.53\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;0.0006610419368371367</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-275.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;0.0006385322194546461</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-260.03\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;0.0004248919722158462</text>\n",
       "<text text-anchor=\"middle\" x=\"109.42\" y=\"-244.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;0.0005743385409004986</text>\n",
       "</g>\n",
       "<!-- ϵ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>ϵ</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"444.85,-153.91 411.6,-114.41 444.85,-74.91 478.1,-114.41 444.85,-153.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"444.85\" y=\"-116.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ϵ</text>\n",
       "<text text-anchor=\"middle\" x=\"444.85\" y=\"-101.11\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;ϵ -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>6&#45;&gt;ϵ</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.22,-171.63C214.24,-176.43 225.58,-180.53 236.85,-183.41 304.35,-200.63 331.51,-215 393.6,-183.41 407.81,-176.18 418.95,-162.84 427.09,-149.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"430.02,-151.72 431.98,-141.31 423.96,-148.23 430.02,-151.72\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-203.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;0.001609519124031067</text>\n",
       "</g>\n",
       "<!-- ϵ&#45;&gt;6 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ϵ&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M436.4,-84.51C429.29,-62.95 416.22,-35.36 393.6,-21.91 333.72,13.71 303.07,-0.27 236.85,-21.91 225.05,-25.76 213.44,-31.18 202.33,-37.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200.79,-34.33 194,-42.46 204.38,-40.34 200.79,-34.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-166.61\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0&#45;0.0001322268508374691</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-150.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1&#45;0.00022260368859861046</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-135.11\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2&#45;0.00014748888497706503</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-119.36\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3&#45;9.171358396997675e&#45;05</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-103.61\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4&#45;0.00010011398262577131</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-87.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5&#45;7.951240695547312e&#45;05</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-72.11\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6&#45;6.252175808185712e&#45;05</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-56.36\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7&#45;7.580733654322103e&#45;05</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-40.61\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8&#45;7.291988731594756e&#45;05</text>\n",
       "<text text-anchor=\"middle\" x=\"315.22\" y=\"-24.86\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">9&#45;5.895936192246154e&#45;05</text>\n",
       "</g>\n",
       "<!-- ϵ&#45;&gt;ϵ -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>ϵ&#45;&gt;ϵ</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M426.06,-132.36C414.66,-151.01 420.92,-171.91 444.85,-171.91 464.29,-171.91 472.07,-158.11 468.18,-142.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"471.4,-141.56 464.23,-133.75 464.97,-144.32 471.4,-141.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"444.85\" y=\"-174.36\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">.&#45;0.0003266185522079468</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x119b4d44a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(learning_result.model)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymodelextractor_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
