{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=False)\n",
    "tokenizer_w_prefix_space = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(sequence, tokenizer):\n",
    "    decoded_sequence = []\n",
    "    for token in sequence:\n",
    "        decoded_sequence.append(tokenizer.decode(token))\n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tokenizers(string):\n",
    "    print(f\"String: {string}\")\n",
    "    encoded_string1 = tokenizer.encode(string)\n",
    "    print(f\"Encoded sequence while using tokenizer without prefix space: {encoded_string1}\")\n",
    "    print(f\"Decoded sequence while using tokenizer without prefix space: {decode_sequence(encoded_string1, tokenizer)}\")\n",
    "    encoded_string2 = tokenizer_w_prefix_space.encode(string)\n",
    "    print(f\"Encoded sequence while using tokenizer without prefix space: {encoded_string2}\")\n",
    "    print(f\"Decoded sequence while using tokenizer with prefix space: {decode_sequence(encoded_string2, tokenizer_w_prefix_space)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with \"medicine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: medicine\n",
      "Encoded sequence while using tokenizer without prefix space: [1150, 291, 500]\n",
      "Decoded sequence while using tokenizer without prefix space: ['med', 'ic', 'ine']\n",
      "Encoded sequence while using tokenizer without prefix space: [9007]\n",
      "Decoded sequence while using tokenizer with prefix space: [' medicine']\n"
     ]
    }
   ],
   "source": [
    "test_tokenizers(\"medicine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with \"astrophysics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: astrophysics\n",
      "Encoded sequence while using tokenizer without prefix space: [459, 10051, 23154]\n",
      "Decoded sequence while using tokenizer without prefix space: ['ast', 'roph', 'ysics']\n",
      "Encoded sequence while using tokenizer without prefix space: [48782, 23154]\n",
      "Decoded sequence while using tokenizer with prefix space: [' astroph', 'ysics']\n"
     ]
    }
   ],
   "source": [
    "test_tokenizers(\"astrophysics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Guide Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_relm_resources.automata_examples.small_study_example import get_small_study_example\n",
    "\n",
    "guide_model = get_small_study_example(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                            return_dict_in_generate=True,\n",
    "                                            pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.gpt2.gpt2_probabilistic_model_wrapper import GPT2_probabilistic_model_wrapper\n",
    "from mini_relm_resources.automata_examples.small_study_example import alphabet\n",
    "\n",
    "wrapper = GPT2_probabilistic_model_wrapper(50, alphabet, device, model, tokenizer)\n",
    "wrapper_w_prefix_space = GPT2_probabilistic_model_wrapper(50, alphabet, device, model, tokenizer_w_prefix_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.guiding_wfa_sequence_generator import GuidingWDFASequenceGenerator\n",
    "guiding_generator = GuidingWDFASequenceGenerator(guide_model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"698pt\" height=\"234pt\"\n",
       " viewBox=\"0.00 0.00 698.48 234.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 230)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-230 694.48,-230 694.48,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-76 0,-38 27,0 54,-38 27,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-41.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-26.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"132.87\" cy=\"-126\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.87\" y=\"-129.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n",
       "<text text-anchor=\"middle\" x=\"132.87\" y=\"-114.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.23,-51.75C59.99,-65.1 84.26,-85.66 103.26,-101.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.8,-104.26 110.69,-108.05 105.32,-98.92 100.8,-104.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-91.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;1</text>\n",
       "</g>\n",
       "<!-- hole -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>hole</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"649.48\" cy=\"-102\" rx=\"28.07\" ry=\"28.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-105.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hole</text>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-90.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;hole -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.54,-32.49C71.48,-27.87 103.59,-22 131.87,-22 131.87,-22 131.87,-22 475.61,-22 533.67,-22 551.02,-28.28 601.48,-57 608.9,-61.23 616.04,-66.88 622.42,-72.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"619.93,-75.21 629.51,-79.72 624.83,-70.22 619.93,-75.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.74\" y=\"-55.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"288.74\" y=\"-40.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"288.74\" y=\"-25.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;hole -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.26,-137.01C163.8,-139.84 170.97,-142.73 177.74,-145 208.1,-155.18 216.08,-157.24 247.74,-162 359.39,-178.77 389.63,-189.36 501.48,-174 547.2,-167.72 561.26,-168.64 601.48,-146 608.85,-141.85 615.96,-136.32 622.33,-130.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"624.63,-133.22 629.42,-123.77 619.78,-128.17 624.63,-133.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.74\" y=\"-214.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"388.74\" y=\"-199.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"388.74\" y=\"-184.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"288.74\" cy=\"-126\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.74\" y=\"-129.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\n",
       "<text text-anchor=\"middle\" x=\"288.74\" y=\"-114.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.97,-126C184.73,-126 222.2,-126 250.17,-126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250,-129.5 260,-126 250,-122.5 250,-129.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.74\" y=\"-129.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;1</text>\n",
       "</g>\n",
       "<!-- hole&#45;&gt;hole -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>hole&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.38,-125.34C630.9,-137.41 636.27,-148.28 649.48,-148.28 658.36,-148.28 663.69,-143.37 665.49,-136.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"668.98,-136.88 665.57,-126.85 661.98,-136.82 668.98,-136.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-197.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-182.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-167.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"649.48\" y=\"-152.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;hole -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>C&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M315.68,-130.03C369.75,-137.56 498.08,-150.87 601.48,-126 606.09,-124.89 610.76,-123.25 615.27,-121.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"616.53,-124.61 624.05,-117.15 613.52,-118.29 616.53,-124.61\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.61\" y=\"-158.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"474.61\" y=\"-143.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"474.61\" cy=\"-77\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.61\" y=\"-80.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "<text text-anchor=\"middle\" x=\"474.61\" y=\"-65.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.13,-112.23C322.6,-106.37 335.45,-99.99 347.74,-96 376.6,-86.64 410.69,-81.86 436.12,-79.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.32,-82.93 445.98,-78.58 435.72,-75.95 436.32,-82.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.74\" y=\"-114.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"388.74\" y=\"-99.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;1</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;hole -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>D&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M500.45,-69.03C526.36,-62.03 567.83,-54.59 601.48,-66 607.97,-68.2 614.26,-71.69 620.02,-75.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"617.88,-78.42 627.95,-81.71 622.13,-72.86 617.88,-78.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"560.48\" y=\"-114.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.48\" y=\"-99.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.48\" y=\"-84.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.48\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1fde6793fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(guide_model)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.syncronic_model_guided_language_model import SyncronicModelGuidedLanguageModel\n",
    "from mini_relm_resources.automata_examples.small_study_example import get_small_study_example\n",
    "\n",
    "property_model = get_small_study_example(wrapper.terminal_symbol)\n",
    "property_model_w_prefix_space = get_small_study_example(wrapper_w_prefix_space.terminal_symbol)\n",
    "\n",
    "syncrhronic_model = SyncronicModelGuidedLanguageModel(wrapper, property_model, model_name=\"GUIDED_GPT2\", max_seq_length=10, normalize_outputs=True, top_k=3)\n",
    "syncrhronic_model_w_prefix_space = SyncronicModelGuidedLanguageModel(wrapper_w_prefix_space, property_model, model_name=\"GUIDED_GPT2\", max_seq_length=10, normalize_outputs=True, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_probabilistic_teacher import PACProbabilisticTeacher\n",
    "from utilities.hypothesis_aware_sample_probabilistic_teacher import HypothesisAwareSampleProbabilisticTeacher\n",
    "from pymodelextractor.learners.observation_tree_learners.bounded_pdfa_quantization_n_ary_tree_learner import BoundedPDFAQuantizationNAryTreeLearner\n",
    "from pythautomata.utilities.probability_partitioner import QuantizationProbabilityPartitionerPlus\n",
    "from pythautomata.model_comparators.wfa_partition_comparison_strategy import WFAPartitionComparator\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "partitioner = QuantizationProbabilityPartitionerPlus(1000)\n",
    "comparator = WFAPartitionComparator(partitioner)\n",
    "epsilon = 0.1\n",
    "delta = epsilon\n",
    "sequence_generator = guiding_generator\n",
    "max_states = 50\n",
    "max_query_length = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = HypothesisAwareSampleProbabilisticTeacher(syncrhronic_model, comparator, 30)\n",
    "teacher_w_prefix_space = HypothesisAwareSampleProbabilisticTeacher(syncrhronic_model_w_prefix_space, comparator, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = BoundedPDFAQuantizationNAryTreeLearner(partitioner, max_states, max_query_length, None, generate_partial_hipothesis = True, pre_cache_queries_for_building_hipothesis = True,  check_probabilistic_hipothesis = False, omit_zero_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n",
      "e:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\pdfa_quantization_n_ary_tree_learner.py:99: UserWarning: Possible infinite loop, last hipothesis has the same size as current hipothesis.\n",
      "Size: 5\n",
      "  warnings.warn('Possible infinite loop, last hipothesis has the same size as current hipothesis.\\nSize: '+str(size))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learning_result \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m learning_result_w_prefix_space \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mlearn(teacher_w_prefix_space, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\bounded_pdfa_quantization_n_ary_tree_learner.py:50\u001b[0m, in \u001b[0;36mBoundedPDFAQuantizationNAryTreeLearner.learn\u001b[1;34m(self, teacher, verbose)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_learning_with_time_bound(teacher, verbose)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumberOfStatesExceededException:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOfStatesExceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\pdfa_quantization_n_ary_tree_learner.py:102\u001b[0m, in \u001b[0;36mPDFAQuantizationNAryTreeLearner.learn\u001b[1;34m(self, teacher, verbose)\u001b[0m\n\u001b[0;32m     99\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPossible infinite loop, last hipothesis has the same size as current hipothesis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSize: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(size))\n\u001b[0;32m    100\u001b[0m last_size \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m--> 102\u001b[0m teacher_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teacher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounterexample\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())                \n\u001b[0;32m    103\u001b[0m model_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlast_token_probabilities(counterexample, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_symbols_sorted)\n\u001b[0;32m    104\u001b[0m ce_is_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability_partitioner\u001b[38;5;241m.\u001b[39mare_in_same_partition(teacher_prob, model_prob)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\pymodelextractor\\teachers\\probabilistic_teacher.py:57\u001b[0m, in \u001b[0;36mProbabilisticTeacher.next_token_probabilities\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m     55\u001b[0m symbols\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m     56\u001b[0m symbols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_symbol] \u001b[38;5;241m+\u001b[39m symbols\n\u001b[1;32m---> 57\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[38;5;28mzip\u001b[39m(symbols, probabilities))\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\pymodelextractor\\teachers\\probabilistic_teacher.py:45\u001b[0m, in \u001b[0;36mProbabilisticTeacher.last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlast_token_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence: Sequence, required_suffixes: \u001b[38;5;28mlist\u001b[39m[Sequence]):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_token_weight_queries_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(required_suffixes)            \n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\utilities\\syncronic_model_guided_language_model.py:126\u001b[0m, in \u001b[0;36mSyncronicModelGuidedLanguageModel.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_sequence_is_defined(sequence):\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mundefined_output\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\utilities\\syncronic_model_guided_language_model.py:102\u001b[0m, in \u001b[0;36mSyncronicModelGuidedLanguageModel._raw_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m    100\u001b[0m     guiding_results \u001b[38;5;241m=\u001b[39m  [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(required_suffixes)\n\u001b[0;32m    101\u001b[0m     projected_required_suffixes \u001b[38;5;241m=\u001b[39m required_suffixes    \n\u001b[1;32m--> 102\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprojected_required_suffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m model_results_full \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    104\u001b[0m j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:48\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_last_token_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence, required_suffixes):\n\u001b[0;32m     47\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m---> 48\u001b[0m     alphabet_symbols_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_token_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m required_suffixes:\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m alphabet_symbols_weights\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:43\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.last_token_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     41\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alphabet\u001b[38;5;241m.\u001b[39msymbols)\n\u001b[0;32m     42\u001b[0m     symbols\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_symbol)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:91\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     88\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     89\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_symbols_probabilities_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Juan\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:108\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_symbols_probabilities_dict\u001b[1;34m(self, input_ids, probs, symbols)\u001b[0m\n\u001b[0;32m    106\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([input_ids[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mid\u001b[39m])])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 108\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m    110\u001b[0m     next_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    878\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    885\u001b[0m         output_attentions,\n\u001b[0;32m    886\u001b[0m     )\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    379\u001b[0m     hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    386\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]]:\n\u001b[0;32m    388\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 389\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m    391\u001b[0m         hidden_states,\n\u001b[0;32m    392\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2545\u001b[0m     )\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_result = learner.learn(teacher, verbose=False)\n",
    "learning_result_w_prefix_space = learner.learn(teacher_w_prefix_space, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"1022pt\" height=\"405pt\"\n",
       " viewBox=\"0.00 0.00 1022.13 404.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 400.99)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-400.99 1018.13,-400.99 1018.13,4 -4,4\"/>\n",
       "<!-- HOLE -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>HOLE</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"973.13\" cy=\"-262.99\" rx=\"37.45\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">HOLE</text>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-251.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- HOLE&#45;&gt;HOLE -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>HOLE&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M955.07,-296.3C954.58,-308.49 960.6,-318.47 973.13,-318.47 981.55,-318.47 987.03,-313.97 989.57,-307.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"992.98,-308.2 990.97,-297.8 986.05,-307.18 992.98,-308.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-367.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-352.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-337.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"973.13\" y=\"-322.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"157.87\" cy=\"-291.99\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.87\" y=\"-295.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I</text>\n",
       "<text text-anchor=\"middle\" x=\"157.87\" y=\"-280.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;HOLE -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.95,-292.15C273.65,-292.52 571.84,-292.52 817.65,-277.99 853.55,-275.87 894,-271.89 924.5,-268.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"924.62,-272.07 934.17,-267.49 923.84,-265.11 924.62,-272.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.66\" y=\"-325.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"497.66\" y=\"-310.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"497.66\" y=\"-295.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "</g>\n",
       "<!-- I,studied -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>I,studied</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"329.7\" cy=\"-217.99\" rx=\"45.92\" ry=\"45.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-221.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I,studied</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-206.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;I,studied -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;I,studied</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.12,-276.46C187.11,-271.76 195.06,-266.83 202.74,-262.99 225.41,-251.66 251.64,-241.81 274.28,-234.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.22,-237.62 283.64,-231.18 273.05,-230.96 275.22,-237.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.24\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;1.0</text>\n",
       "</g>\n",
       "<!-- I,studied&#45;&gt;HOLE -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>I,studied&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.06,-220.25C462.18,-224.66 655.33,-235.12 817.65,-247.99 853.5,-250.84 893.95,-254.79 924.47,-257.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"923.83,-261.38 934.14,-258.93 924.55,-254.42 923.83,-261.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"718.66\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"718.66\" y=\"-251.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- I,studied,astrophysics -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>I,studied,astrophysics</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"718.66\" cy=\"-98.99\" rx=\"98.99\" ry=\"98.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"718.66\" y=\"-102.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I,studied,astrophysics</text>\n",
       "<text text-anchor=\"middle\" x=\"718.66\" y=\"-87.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "<!-- I,studied&#45;&gt;I,studied,astrophysics -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>I,studied&#45;&gt;I,studied,astrophysics</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M371.67,-198.75C378.93,-195.64 386.46,-192.59 393.66,-189.99 464.97,-164.28 547.22,-141.25 611.01,-124.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"611.6,-128.26 620.42,-122.39 609.86,-121.48 611.6,-128.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.66\" y=\"-208.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0.001119266571591889</text>\n",
       "<text text-anchor=\"middle\" x=\"497.66\" y=\"-193.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0.9988807334284081</text>\n",
       "</g>\n",
       "<!-- I,studied,astrophysics&#45;&gt;HOLE -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>I,studied,astrophysics&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M816.97,-113.06C851.68,-121.95 889.19,-136.43 917.65,-159.99 935.48,-174.76 948.26,-196.9 956.94,-216.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"953.63,-218.05 960.65,-225.99 960.11,-215.41 953.63,-218.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"876.65\" y=\"-208.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"876.65\" y=\"-193.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"876.65\" y=\"-178.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"876.65\" y=\"-163.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!--  -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-359.99 0,-321.99 34,-283.99 68,-321.99 34,-359.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-325.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"></text>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-310.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;HOLE -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.77,-331.82C84.09,-340.57 122.44,-351.99 156.87,-351.99 156.87,-351.99 156.87,-351.99 719.66,-351.99 797.76,-351.99 882.12,-313.64 930.86,-287.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"932.31,-290.49 939.38,-282.6 928.93,-284.36 932.31,-290.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-385.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-370.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-355.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;I -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.35,-315.26C79.55,-311.03 101.95,-305.51 120.62,-300.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.34,-304.34 130.22,-298.56 119.67,-297.55 121.34,-304.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-312.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2ac8a7d2b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(exporter.create_graph(learning_result.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"1015pt\" height=\"405pt\"\n",
       " viewBox=\"0.00 0.00 1015.13 404.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 400.99)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-400.99 1011.13,-400.99 1011.13,4 -4,4\"/>\n",
       "<!-- HOLE -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>HOLE</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"966.13\" cy=\"-262.99\" rx=\"37.45\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">HOLE</text>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-251.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- HOLE&#45;&gt;HOLE -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>HOLE&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M948.07,-296.3C947.58,-308.49 953.6,-318.47 966.13,-318.47 974.55,-318.47 980.03,-313.97 982.57,-307.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"985.98,-308.2 983.97,-297.8 979.05,-307.18 985.98,-308.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-367.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-352.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-337.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"966.13\" y=\"-322.27\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"157.87\" cy=\"-291.99\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.87\" y=\"-295.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I</text>\n",
       "<text text-anchor=\"middle\" x=\"157.87\" y=\"-280.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;HOLE -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.98,-292.14C273.12,-292.48 567.74,-292.38 810.65,-277.99 846.55,-275.87 887,-271.88 917.5,-268.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"917.62,-272.06 927.17,-267.48 916.84,-265.11 917.62,-272.06\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.16\" y=\"-325.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"494.16\" y=\"-310.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"494.16\" y=\"-295.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "</g>\n",
       "<!-- I,studied -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>I,studied</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"329.7\" cy=\"-217.99\" rx=\"45.92\" ry=\"45.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-221.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I,studied</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-206.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;I,studied -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;I,studied</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.12,-276.46C187.11,-271.76 195.06,-266.83 202.74,-262.99 225.41,-251.66 251.64,-241.81 274.28,-234.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.22,-237.62 283.64,-231.18 273.05,-230.96 275.22,-237.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.24\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;1.0</text>\n",
       "</g>\n",
       "<!-- I,studied&#45;&gt;HOLE -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>I,studied&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.07,-220.31C461.28,-224.77 651.07,-235.26 810.65,-247.99 846.5,-250.85 886.95,-254.81 917.47,-257.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"916.83,-261.39 927.14,-258.94 917.55,-254.43 916.83,-261.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.66\" y=\"-266.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"711.66\" y=\"-251.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- I,studied,astrophysics -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>I,studied,astrophysics</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"711.66\" cy=\"-98.99\" rx=\"98.99\" ry=\"98.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.66\" y=\"-102.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I,studied,astrophysics</text>\n",
       "<text text-anchor=\"middle\" x=\"711.66\" y=\"-87.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "<!-- I,studied&#45;&gt;I,studied,astrophysics -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>I,studied&#45;&gt;I,studied,astrophysics</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M371.68,-198.79C378.94,-195.67 386.47,-192.61 393.66,-189.99 462.69,-164.88 542.15,-142.08 604.25,-125.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"605,-129.01 613.77,-123.07 603.21,-122.24 605,-129.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"494.16\" y=\"-208.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0.14258990784456949</text>\n",
       "<text text-anchor=\"middle\" x=\"494.16\" y=\"-193.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0.8574100921554305</text>\n",
       "</g>\n",
       "<!-- I,studied,astrophysics&#45;&gt;HOLE -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>I,studied,astrophysics&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M809.97,-113.06C844.68,-121.95 882.19,-136.43 910.65,-159.99 928.48,-174.76 941.26,-196.9 949.94,-216.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"946.63,-218.05 953.65,-225.99 953.11,-215.41 946.63,-218.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"869.65\" y=\"-208.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"869.65\" y=\"-193.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"869.65\" y=\"-178.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"869.65\" y=\"-163.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!--  -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-359.99 0,-321.99 34,-283.99 68,-321.99 34,-359.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-325.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"></text>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-310.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;HOLE -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.77,-331.82C84.09,-340.57 122.44,-351.99 156.87,-351.99 156.87,-351.99 156.87,-351.99 712.66,-351.99 790.76,-351.99 875.12,-313.64 923.86,-287.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"925.31,-290.49 932.38,-282.6 921.93,-284.36 925.31,-290.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-385.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-370.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"329.7\" y=\"-355.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;I -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.35,-315.26C79.55,-311.03 101.95,-305.51 120.62,-300.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.34,-304.34 130.22,-298.56 119.67,-297.55 121.34,-304.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.5\" y=\"-312.79\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">I&#45;1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2ac86be51f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(exporter.create_graph(learning_result_w_prefix_space.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOS symbol with tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.eos_token, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0623, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    next_token = torch.argmax(torch.softmax(model(tokenizer.encode(tokenizer.eos_token, return_tensors=\"pt\")).logits, dim=-1))\n",
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOS as nex symbol with tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.bos_token, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1286)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    next_token_probabilities = torch.softmax(model(tokenizer.encode(\"I\", return_tensors=\"pt\")).logits, dim=-1)[0][0]\n",
    "    bos_probability = next_token_probabilities[tokenizer.bos_token_id] * 100\n",
    "bos_probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymodelextractor_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
