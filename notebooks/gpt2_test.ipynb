{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the LLM, in this case we are using gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=True, local_files_only = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                            return_dict_in_generate=True,\n",
    "                                            pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.gpt2.gpt2_probabilistic_model_wrapper import GPT2_probabilistic_model_wrapper\n",
    "from mini_relm_resources.automata_examples.man_woman_wfa import alphabet\n",
    "\n",
    "wrapper = GPT2_probabilistic_model_wrapper(50, alphabet, device, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_relm_resources.automata_examples.man_woman_wfa import get_man_woman_wfa\n",
    "guiding_wfa = get_man_woman_wfa(wrapper.terminal_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.guiding_wfa_sequence_generator import GuidingWDFASequenceGenerator\n",
    "generator = GuidingWDFASequenceGenerator(guiding_wfa, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The,woman,studied,music,\n",
       " The,man,studied,art,\n",
       " The,man,studied,engineering,\n",
       " The,man,studied,science,\n",
       " The,woman,studied,medicine,\n",
       " The,man,studied,medicine,\n",
       " The,man,studied,maths,\n",
       " The,woman,studied,science,\n",
       " The,woman,studied,medicine,\n",
       " The,man,studied,art]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"946pt\" height=\"607pt\"\n",
       " viewBox=\"0.00 0.00 945.83 606.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 602.5)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-602.5 941.83,-602.5 941.83,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-79 0,-39.5 27,0 54,-39.5 27,-79\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-41.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-26.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.93\" cy=\"-284.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.93\" y=\"-286.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n",
       "<text text-anchor=\"middle\" x=\"150.93\" y=\"-271.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M39.04,-61.67C60.27,-104.34 106.97,-198.17 132.47,-249.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.31,-250.92 136.9,-258.31 135.57,-247.8 129.31,-250.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"88.5\" y=\"-193.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;1</text>\n",
       "</g>\n",
       "<!-- hole -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>hole</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"859.08\" cy=\"-229.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-231.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hole</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-216.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;hole -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.26,-34.61C75.7,-29.91 115.34,-23.5 149.93,-23.5 149.93,-23.5 149.93,-23.5 643.9,-23.5 697.36,-23.5 719.28,-12.82 762.33,-44.5 811.03,-80.33 836.96,-148.26 849.09,-191.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"845.71,-191.98 851.69,-200.72 852.46,-190.15 845.71,-191.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-151.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-136.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-120.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-104.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-88.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-73.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-57.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-41.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-25.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;hole -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.65,-311.44C173.4,-363.42 213.86,-472.5 293.54,-472.5 293.54,-472.5 293.54,-472.5 643.9,-472.5 752.31,-472.5 818.9,-334.72 845.18,-266.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"848.42,-267.98 848.66,-257.38 841.87,-265.51 848.42,-267.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-585.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-569.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-553.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-537.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-522.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-506.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-490.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-474.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"294.54\" cy=\"-284.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"294.54\" y=\"-286.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\n",
       "<text text-anchor=\"middle\" x=\"294.54\" y=\"-271.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.23,-284.5C200.78,-284.5 231.11,-284.5 255.11,-284.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.81,-288 264.81,-284.5 254.81,-281 254.81,-288\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.74\" y=\"-302.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"222.74\" y=\"-286.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;1</text>\n",
       "</g>\n",
       "<!-- hole&#45;&gt;hole -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>hole&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M837.29,-247.42C829.13,-261.28 836.4,-275.43 859.08,-275.43 875.74,-275.43 884.09,-267.8 884.12,-258.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"887.53,-257.45 881.32,-248.87 880.82,-259.45 887.53,-257.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-419.63\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-403.88\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-388.13\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-372.38\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-356.63\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-340.88\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-325.13\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-309.38\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-293.63\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"859.08\" y=\"-277.88\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;hole -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>C&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322.64,-288.77C384.75,-297.79 541.97,-316.23 670.83,-294.5 725.81,-285.23 786.19,-261.66 823.13,-245.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"824.23,-248.94 831.96,-241.7 821.4,-242.54 824.23,-248.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-432.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-417.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-401.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-385.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-369.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-354.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-338.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-306.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"468.72\" cy=\"-224.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-226.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "<text text-anchor=\"middle\" x=\"468.72\" y=\"-211.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.32,-275.52C350.48,-265.35 398.2,-248.73 431.19,-237.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.05,-240.64 440.34,-234.04 429.75,-234.03 432.05,-240.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"377.22\" y=\"-269.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;1</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;hole -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>D&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.03,-224.85C564.86,-225.72 741.15,-227.99 819.54,-229\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"819.25,-232.5 829.29,-229.13 819.34,-225.5 819.25,-232.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-277.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-261.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-245.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-229.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"642.9\" cy=\"-89.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-91.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">E</text>\n",
       "<text text-anchor=\"middle\" x=\"642.9\" y=\"-76.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;E -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>D&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M475.97,-197.51C483.18,-172.57 497.51,-136.38 523.47,-116 546.08,-98.26 578.22,-91.9 603.31,-89.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"603.36,-93.33 613.13,-89.23 602.93,-86.35 603.36,-93.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-197.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-181.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-166.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-150.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-134.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"560.22\" y=\"-118.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;1</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;hole -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>E&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M664.4,-71.19C671.61,-65.87 680.11,-60.75 688.83,-58 719.99,-48.17 734.16,-41.46 762.33,-58 810.99,-86.56 836.75,-149.83 848.88,-191.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"845.48,-191.86 851.54,-200.55 852.22,-189.98 845.48,-191.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-202.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-186.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-155.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-139.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-123.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-108.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-92.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-76.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"725.58\" y=\"-60.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x26484567e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(guiding_wfa)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.syncronic_model_guided_language_model import SyncronicModelGuidedLanguageModel\n",
    "from mini_relm_resources.automata_examples.man_woman_wfa import get_man_woman_wfa\n",
    "property_model = get_man_woman_wfa(wrapper.terminal_symbol)\n",
    "syncrhronic_model = SyncronicModelGuidedLanguageModel(wrapper, property_model, model_name=\"GUIDED_GPT2\", max_seq_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_probabilistic_teacher import PACProbabilisticTeacher\n",
    "from pymodelextractor.learners.observation_tree_learners.bounded_pdfa_quantization_n_ary_tree_learner import BoundedPDFAQuantizationNAryTreeLearner\n",
    "from pythautomata.utilities.probability_partitioner import TopKProbabilityPartitioner, QuantizationProbabilityPartitioner, RankingPartitioner\n",
    "from pythautomata.model_comparators.wfa_partition_comparison_strategy import WFAPartitionComparator\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "partitioner = QuantizationProbabilityPartitioner(10)\n",
    "comparator = WFAPartitionComparator(partitioner)\n",
    "epsilon = 0.1\n",
    "delta = epsilon\n",
    "sequence_generator = generator\n",
    "max_states = 100\n",
    "max_query_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher  = PACProbabilisticTeacher(wrapper, epsilon = epsilon, delta = delta, max_seq_length = None, comparator = comparator, sequence_generator=sequence_generator, compute_epsilon_star=False)\n",
    "learner = BoundedPDFAQuantizationNAryTreeLearner(partitioner, max_states, max_query_length, None, generate_partial_hipothesis = True, pre_cache_queries_for_building_hipothesis = True,  check_probabilistic_hipothesis = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learning_result \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\bounded_pdfa_quantization_n_ary_tree_learner.py:50\u001b[0m, in \u001b[0;36mBoundedPDFAQuantizationNAryTreeLearner.learn\u001b[1;34m(self, teacher, verbose)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_learning_with_time_bound(teacher, verbose)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumberOfStatesExceededException:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOfStatesExceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\pdfa_quantization_n_ary_tree_learner.py:83\u001b[0m, in \u001b[0;36mPDFAQuantizationNAryTreeLearner.learn\u001b[1;34m(self, teacher, verbose)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbols:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree\u001b[38;5;241m.\u001b[39msift(Sequence([symbol]))\n\u001b[1;32m---> 83\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtentative_hypothesis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[0;32m     85\u001b[0m last_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mweighted_states)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\pdfa_quantization_n_ary_tree_learner.py:135\u001b[0m, in \u001b[0;36mPDFAQuantizationNAryTreeLearner.tentative_hypothesis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m updated_tree:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_cache_queries_for_building_hipothesis:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_queries_for_building_hipothesis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m leaf_str, leaf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree\u001b[38;5;241m.\u001b[39mleaves\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    138\u001b[0m         initial_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m leaf_str \u001b[38;5;241m==\u001b[39m epsilon \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\pymodelextractor\\learners\\observation_tree_learners\\pdfa_quantization_n_ary_tree_learner.py:235\u001b[0m, in \u001b[0;36mClassificationTree.cache_queries_for_building_hipothesis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m                 queries\u001b[38;5;241m.\u001b[39madd(query)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queries)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 235\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teacher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token_probabilities_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_token_probabilities_cache\u001b[38;5;241m.\u001b[39mupdate(results)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\pymodelextractor\\teachers\\probabilistic_teacher.py:106\u001b[0m, in \u001b[0;36mProbabilisticTeacher.next_token_probabilities_batch\u001b[1;34m(self, sequences)\u001b[0m\n\u001b[0;32m    104\u001b[0m     final_results\u001b[38;5;241m.\u001b[39mupdate(results_already_in_cache)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:        \n\u001b[1;32m--> 106\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     results_od \u001b[38;5;241m=\u001b[39m [OrderedDict(\u001b[38;5;28mzip\u001b[39m(symbols, x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m    108\u001b[0m     final_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(sequences, results_od)\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:62\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.get_last_token_weights_batch\u001b[1;34m(self, sequences, required_suffixes)\u001b[0m\n\u001b[0;32m     60\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences:\n\u001b[1;32m---> 62\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:47\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m     44\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#alphabet_symbols_weights = self.next_symbol_probas(sequence)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#alphabet_symbols_weights = {Sequence() + k: alphabet_symbols_weights[k] for k in alphabet_symbols_weights.keys()}\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m alphabet_symbols_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_token_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m required_suffixes:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m alphabet_symbols_weights:\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:40\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.last_token_probability\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m     38\u001b[0m symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alphabet\u001b[38;5;241m.\u001b[39msymbols)\n\u001b[0;32m     39\u001b[0m symbols\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_symbol)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:93\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_probability\u001b[1;34m(self, sequence, symbols, normalize, top_k)\u001b[0m\n\u001b[0;32m     88\u001b[0m         probs \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mscatter(_axis,\n\u001b[0;32m     89\u001b[0m                         top_k_val\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m     90\u001b[0m                         top_k_val\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     91\u001b[0m         probs \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(probs)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_words_probabilities_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Repos\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:101\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_words_probabilities_dict\u001b[1;34m(self, probs, symbols, normalize)\u001b[0m\n\u001b[0;32m     99\u001b[0m word_probabilities \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m symbols:\n\u001b[1;32m--> 101\u001b[0m     word_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Convert each tokenization to input IDs\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     input_ids_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m word_tokens]\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:396\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.tokenize\u001b[1;34m(self, text, pair, add_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, pair: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, add_special_tokens: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mpair, add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mtokens()\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2982\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2972\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2973\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2974\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2975\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2980\u001b[0m )\n\u001b[1;32m-> 2982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   2983\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2984\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2985\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2986\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2987\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2988\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2989\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2990\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2991\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2992\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2993\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2994\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2995\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2996\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2997\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2998\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2999\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3000\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3001\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\models\\gpt2\\tokenization_gpt2_fast.py:172\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:576\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    556\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m    575\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[1;32m--> 576\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    577\u001b[0m         batched_input,\n\u001b[0;32m    578\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m    579\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    580\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    581\u001b[0m         truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    582\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    583\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m    584\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    585\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    586\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    587\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    588\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    589\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    590\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    591\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    592\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    594\u001b[0m     )\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\models\\gpt2\\tokenization_gpt2_fast.py:162\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Digital\\anaconda3\\envs\\pymodelextractor_exp\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:504\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    497\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    498\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    501\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    502\u001b[0m )\n\u001b[1;32m--> 504\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    516\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[0;32m    518\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[0;32m    528\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_result = learner.learn(teacher, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.sequence import Sequence\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "test_seq = Sequence([SymbolStr(\"The\"),SymbolStr(\"man\"),SymbolStr(\"studied\"), SymbolStr(\"science\")])\n",
    "#teacher.next_token_probabilities(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def next_token_probabilities(model, sequence):\n",
    "        symbols = list(model.alphabet.symbols)\n",
    "        symbols.sort()\n",
    "        symbols = [model.terminal_symbol] + symbols\n",
    "        probabilities = model.get_last_token_weights(sequence, symbols)\n",
    "        probabilities = OrderedDict(zip(symbols, probabilities))\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, 0.40289263328594505),\n",
       "             (The, 0.20153499326332777),\n",
       "             (art, 0.041914323999251615),\n",
       "             (engineering, 0.008062168437993067),\n",
       "             (man, 0.11958741717872891),\n",
       "             (maths, 0.02194084125338335),\n",
       "             (medicine, 0.003204878924567717),\n",
       "             (music, 0.052551288133534345),\n",
       "             (science, 0.11126551560592197),\n",
       "             (studied, 0.011291937707357619),\n",
       "             (woman, 0.025754002209988622)])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(wrapper, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, 1),\n",
       "             (The, 0),\n",
       "             (art, 0),\n",
       "             (engineering, 0),\n",
       "             (man, 0),\n",
       "             (maths, 0),\n",
       "             (medicine, 0),\n",
       "             (music, 0),\n",
       "             (science, 0),\n",
       "             (studied, 0),\n",
       "             (woman, 0)])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(guiding_wfa, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(<|endoftext|>, 0.40289263328594505),\n",
       "             (The, 0.0),\n",
       "             (art, 0.0),\n",
       "             (engineering, 0.0),\n",
       "             (man, 0.0),\n",
       "             (maths, 0.0),\n",
       "             (medicine, 0.0),\n",
       "             (music, 0.0),\n",
       "             (science, 0.0),\n",
       "             (studied, 0.0),\n",
       "             (woman, 0.0)])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probabilities(syncrhronic_model, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"1080pt\" height=\"602pt\"\n",
       " viewBox=\"0.00 0.00 1080.00 601.71\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.890756 0.890756) rotate(0) translate(4 671.5)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-671.5 1208.45,-671.5 1208.45,4 -4,4\"/>\n",
       "<!-- The -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>The</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.93\" cy=\"-350.5\" rx=\"27.93\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.93\" y=\"-352.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The</text>\n",
       "<text text-anchor=\"middle\" x=\"150.93\" y=\"-337.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- music -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>music</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1125.7\" cy=\"-293.5\" rx=\"34.65\" ry=\"34.65\"/>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-295.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-280.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- The&#45;&gt;music -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>The&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.15,-377.06C178.23,-429.54 226.73,-541.5 311.4,-541.5 311.4,-541.5 311.4,-541.5 835.39,-541.5 961.5,-541.5 1060.22,-403.99 1102.41,-333.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1105.38,-335.6 1107.45,-325.21 1099.36,-332.05 1105.38,-335.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-654.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-638.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-622.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-606.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-591.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-575.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-559.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-543.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>The,man</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"312.4\" cy=\"-350.5\" rx=\"45.79\" ry=\"45.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.4\" y=\"-352.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man</text>\n",
       "<text text-anchor=\"middle\" x=\"312.4\" y=\"-337.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- The&#45;&gt;The,man -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>The&#45;&gt;The,man</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.34,-350.5C200.04,-350.5 229.16,-350.5 254.78,-350.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.76,-354 264.76,-350.5 254.76,-347 254.76,-354\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.74\" y=\"-368.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"222.74\" y=\"-352.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;1</text>\n",
       "</g>\n",
       "<!-- music&#45;&gt;music -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>music&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1101.79,-319.23C1097.52,-333.28 1105.5,-346.15 1125.7,-346.15 1140.23,-346.15 1148.43,-339.5 1150.31,-330.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1153.82,-330.51 1149.71,-320.74 1146.83,-330.94 1153.82,-330.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-490.35\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-474.6\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-458.85\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-443.1\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-427.35\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-411.6\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-395.85\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-380.1\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-364.35\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1125.7\" y=\"-348.6\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man&#45;&gt;music -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>The,man&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M358.13,-356.41C461.26,-368.84 723.3,-393.52 937.45,-355.5 988.85,-346.37 1045.44,-326.13 1082.81,-311.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1083.93,-314.57 1091.89,-307.58 1081.3,-308.08 1083.93,-314.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-503.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-488.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-472.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-456.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-440.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-425.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-409.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-393.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-377.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man,studied -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>The,man,studied</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"544.76\" cy=\"-279.5\" rx=\"77.07\" ry=\"77.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-281.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man,studied</text>\n",
       "<text text-anchor=\"middle\" x=\"544.76\" y=\"-266.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- The,man&#45;&gt;The,man,studied -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>The,man&#45;&gt;The,man,studied</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.46,-337.23C385.49,-328.28 424.75,-316.18 459.83,-305.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"460.59,-308.8 469.11,-302.51 458.53,-302.11 460.59,-308.8\"/>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-331.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;1</text>\n",
       "</g>\n",
       "<!-- The,man,studied&#45;&gt;music -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>The,man,studied&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.04,-281.34C744.34,-284.3 980.57,-290.01 1079.45,-292.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.21,-295.9 1089.29,-292.64 1079.38,-288.9 1079.21,-295.9\"/>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-338.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-322.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-306.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-290.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man,studied,music -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>The,man,studied,music</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"834.39\" cy=\"-154.5\" rx=\"103.06\" ry=\"103.06\"/>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-156.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man,studied,music</text>\n",
       "<text text-anchor=\"middle\" x=\"834.39\" y=\"-141.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- The,man,studied&#45;&gt;The,man,studied,music -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>The,man,studied&#45;&gt;The,man,studied,music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M593.63,-219.84C607.2,-206.43 622.92,-193.63 639.83,-185 664.26,-172.53 692.51,-164.89 719.74,-160.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"720.09,-163.76 729.43,-158.76 719.01,-156.84 720.09,-163.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-265.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-249.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-218.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-202.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"676.58\" y=\"-186.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;1</text>\n",
       "</g>\n",
       "<!-- The,man,studied,music&#45;&gt;music -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>The,man,studied,music&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M929.7,-114.02C962.88,-105.96 999.27,-104.58 1028.95,-122 1075.29,-149.2 1100.86,-207.88 1113.67,-248.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1110.25,-249.77 1116.45,-258.36 1116.96,-247.78 1110.25,-249.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-266.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-250.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-235.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-219.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-203.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-187.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-172.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-156.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-140.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"992.2\" y=\"-124.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!--  -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-79 0,-39.5 27,0 54,-39.5 27,-79\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-41.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"></text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-26.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;The -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>&#45;&gt;The</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M37.67,-64.16C59.07,-118.76 110.55,-250.05 135.66,-314.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.29,-315.08 139.2,-323.12 138.8,-312.53 132.29,-315.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"88.5\" y=\"-233.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;1</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;music -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>&#45;&gt;music</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.26,-34.61C75.7,-29.91 115.34,-23.5 149.93,-23.5 149.93,-23.5 149.93,-23.5 835.39,-23.5 928.65,-23.5 967.31,-34.52 1028.95,-104.5 1067.03,-147.74 1094.36,-208.82 1109.84,-249.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1106.52,-250.85 1113.27,-259.02 1113.09,-248.43 1106.52,-250.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-151.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-136.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-120.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-104.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-88.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-73.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-57.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-41.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">studied&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"412.93\" y=\"-25.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x26483254520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(learning_result.model)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymodelextractor_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
