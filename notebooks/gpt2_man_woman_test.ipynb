{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the LLM, in this case we are using gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Downloads\\Programs\\conda\\envs\\GuidedNeuralChecker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=False, local_files_only = True, bos_token='<|startoftext|>', eos_token='<|endoftext|>')\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_id, use_fast=True, add_prefix_space=True, local_files_only = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                            return_dict_in_generate=True,\n",
    "                                            pad_token_id=tokenizer.eos_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[459, 31142]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"astrology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[459, 10051, 23154]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"astrophysics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' astrophysics'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([48782, 23154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50257]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.bos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m50256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:775\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m    777\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\modeling_utils.py:4194\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4190\u001b[0m \u001b[38;5;124;03mShows a one-time warning if the input_ids appear to contain padding and no attention mask was given.\u001b[39;00m\n\u001b[0;32m   4191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4193\u001b[0m \u001b[38;5;66;03m# Skip the check during tracing.\u001b[39;00m\n\u001b[1;32m-> 4194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_fx_proxy(input_ids) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_torchdynamo_compiling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   4195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\utils\\import_utils.py:614\u001b[0m, in \u001b[0;36mis_torchdynamo_compiling\u001b[1;34m()\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 614\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdynamo\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dynamo\u001b[38;5;241m.\u001b[39mis_compiling()\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:62\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[0;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[0;32m     59\u001b[0m     GuardedCode,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputGraph\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExecutionRecord\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslator, SpeculationLog\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\output_graph.py:89\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     checkpoint_params,\n\u001b[0;32m     74\u001b[0m     CleanupHook,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     same,\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphArg, TrackedFake, VariableBuilder, wrap_fx_proxy\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     92\u001b[0m     NumpyNdarrayVariable,\n\u001b[0;32m     93\u001b[0m     SymNodeVariable,\n\u001b[0;32m     94\u001b[0m     TensorVariable,\n\u001b[0;32m     95\u001b[0m     UnspecializedPythonVariable,\n\u001b[0;32m     96\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\variables\\builder.py:143\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    127\u001b[0m     AutogradFunctionContextVariable,\n\u001b[0;32m    128\u001b[0m     AutogradFunctionVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m     TypingVariable,\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FSDPManagedNNModuleVariable, UnspecializedNNModuleVariable\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizerVariable\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    145\u001b[0m     NumpyNdarrayVariable,\n\u001b[0;32m    146\u001b[0m     SymNodeVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     UnspecializedPythonVariable,\n\u001b[0;32m    150\u001b[0m )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch_special_class_types, TorchVariable\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\variables\\optimizer.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mark_static_address\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrSource, GetItemSource, GlobalWeakRefSource\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\decorators.py:141\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Customize which functions TorchDynamo will exclude in the generated\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    graph and force a graph break on.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    single `torch.add()` op.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _disallow_in_graph_helper(throw_if_not_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(fn)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129;43m@_disallow_in_graph_helper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mthrow_if_not_allowed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mgraph_break\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Force a graph break\"\"\"\u001b[39;49;00m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\decorators.py:109\u001b[0m, in \u001b[0;36m_disallow_in_graph_helper.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m throw_if_not_allowed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allowed_functions\u001b[38;5;241m.\u001b[39mis_allowed(fn):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncorrectUsage(\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisallow_in_graph is expected to be used on an already allowed callable (like torch.* ops). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed callables means callables that TorchDynamo puts as-is in the extracted graph.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n\u001b[1;32m--> 109\u001b[0m \u001b[43mallowed_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_allowed_function_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m allowed_functions\u001b[38;5;241m.\u001b[39m_disallowed_function_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(fn))\n\u001b[0;32m    111\u001b[0m allowed_functions\u001b[38;5;241m.\u001b[39m_allowed_user_defined_function_ids\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mid\u001b[39m(fn))\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:88\u001b[0m, in \u001b[0;36mFunctionIdSet.remove\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m---> 88\u001b[0m     function_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m function_ids:\n\u001b[0;32m     90\u001b[0m         function_ids\u001b[38;5;241m.\u001b[39mremove(idx)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:69\u001b[0m, in \u001b[0;36mFunctionIdSet.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:417\u001b[0m, in \u001b[0;36m_allowed_function_ids\u001b[1;34m()\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;129m@FunctionIdSet\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_allowed_function_ids\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_allowed_objs_and_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mobject_ids\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:375\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids\u001b[1;34m(record, c_binding_only)\u001b[0m\n\u001b[0;32m    372\u001b[0m                     heuristic_record_if_in_graph_function(obj, module, name)\n\u001b[0;32m    373\u001b[0m                 torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m _find_torch_objects(math)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtrace_distributed:\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:363\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    360\u001b[0m         obj\n\u001b[0;32m    361\u001b[0m     ):\n\u001b[0;32m    362\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 363\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record:\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:363\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    360\u001b[0m         obj\n\u001b[0;32m    361\u001b[0m     ):\n\u001b[0;32m    362\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 363\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record:\n",
      "    \u001b[1;31m[... skipping similar frames: gen_allowed_objs_and_ids.<locals>._find_torch_objects at line 363 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:363\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    360\u001b[0m         obj\n\u001b[0;32m    361\u001b[0m     ):\n\u001b[0;32m    362\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 363\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record:\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:364\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    362\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         _find_torch_objects(obj)\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43m_is_allowed_module_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record:\n\u001b[0;32m    366\u001b[0m         heuristic_record_if_ctx_manager(obj, module, name)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:315\u001b[0m, in \u001b[0;36mgen_allowed_objs_and_ids.<locals>._is_allowed_module_prefix\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtrace_distributed:\n\u001b[0;32m    313\u001b[0m     disallowed_modules\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 315\u001b[0m allowed_modules_dot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([x \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m allowed_modules])\n\u001b[0;32m    316\u001b[0m module \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(obj)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtrace_distributed:\n\u001b[0;32m    313\u001b[0m     disallowed_modules\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 315\u001b[0m allowed_modules_dot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([x \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m allowed_modules])\n\u001b[0;32m    316\u001b[0m module \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(obj)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.softmax(model(torch.tensor([[50256]])).logits, dim=-1).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ysics'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([23154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'case_studies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcase_studies\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt2_probabilistic_model_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2_probabilistic_model_wrapper\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmini_relm_resources\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomata_examples\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mman_woman_wfa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alphabet\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpythautomata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_types\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'case_studies'"
     ]
    }
   ],
   "source": [
    "from case_studies.gpt2.gpt2_probabilistic_model_wrapper import GPT2_probabilistic_model_wrapper\n",
    "from mini_relm_resources.automata_examples.man_woman_wfa import alphabet\n",
    "from pythautomata.base_types.sequence import Sequence\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "#prompt = Sequence([SymbolStr('The')])\n",
    "wrapper = GPT2_probabilistic_model_wrapper(50, alphabet, device, model, tokenizer)\n",
    "#from utilities.mock_probabilistic_model import MockProbabilisticModel\n",
    "#from pythautomata.base_types.symbol import SymbolStr\n",
    "#terminal_symbol = SymbolStr(tokenizer.eos_token)\n",
    "#wrapper = MockProbabilisticModel(alphabet, terminal_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_token_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSymbolStr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwoman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:48\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.get_last_token_weights\u001b[1;34m(self, sequence, required_suffixes)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_last_token_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence, required_suffixes):\n\u001b[0;32m     47\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m---> 48\u001b[0m     alphabet_symbols_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_token_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired_suffixes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m required_suffixes:\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m alphabet_symbols_weights\n",
      "File \u001b[1;32mc:\\Users\\juan1\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:43\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper.last_token_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     41\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alphabet\u001b[38;5;241m.\u001b[39msymbols)\n\u001b[0;32m     42\u001b[0m     symbols\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_symbol)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\Ort\\NeuralChecker\\pymodelextractor_model_guided_extraction\\notebooks\\..\\case_studies\\gpt2\\gpt2_probabilistic_model_wrapper.py:87\u001b[0m, in \u001b[0;36mGPT2_probabilistic_model_wrapper._get_probability\u001b[1;34m(self, sequence, symbols)\u001b[0m\n\u001b[0;32m     84\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_ids_sequence_from_tokens(str_seq)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 87\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     89\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:837\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    834\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_layer)\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 837\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwte\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[0;32m    839\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juan1\\anaconda3\\envs\\LearnAut\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "wrapper.get_last_token_weights(Sequence([SymbolStr('The')]), [\"man\", \"woman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_relm_resources.automata_examples.man_woman_wfa import get_man_woman_wfa\n",
    "guiding_wfa = get_man_woman_wfa(wrapper.terminal_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'guiding_wfa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpythautomata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguiding_wfa_sequence_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GuidingWDFASequenceGenerator\n\u001b[1;32m----> 2\u001b[0m guiding_generator \u001b[38;5;241m=\u001b[39m GuidingWDFASequenceGenerator(\u001b[43mguiding_wfa\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'guiding_wfa' is not defined"
     ]
    }
   ],
   "source": [
    "from pythautomata.utilities.guiding_wfa_sequence_generator import GuidingWDFASequenceGenerator\n",
    "guiding_generator = GuidingWDFASequenceGenerator(guiding_wfa, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " The,man,was trained in,astrophysics,\n",
       " The,woman,\n",
       " The,man,was trained in,art,\n",
       " The,\n",
       " The,\n",
       " The,\n",
       " The,man,was trained in,engineering,\n",
       " ,\n",
       " The]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guiding_generator.generate_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"1049pt\" height=\"671pt\"\n",
       " viewBox=\"0.00 0.00 1049.48 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-667 1045.48,-667 1045.48,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"27,-76 0,-38 27,0 54,-38 27,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-41.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">A</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-26.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.87\" cy=\"-303\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.87\" y=\"-306.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">B</text>\n",
       "<text text-anchor=\"middle\" x=\"150.87\" y=\"-291.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.39,-60.59C59.76,-107.06 108.75,-213.59 134.07,-268.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.82,-269.94 138.17,-277.57 137.18,-267.02 130.82,-269.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"89\" y=\"-206.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;1</text>\n",
       "</g>\n",
       "<!-- hole -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>hole</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"951.48\" cy=\"-250\" rx=\"28.07\" ry=\"28.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-253.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">hole</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-238.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;hole -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.79,-33.2C75.19,-28.49 115.09,-22 149.87,-22 149.87,-22 149.87,-22 694.48,-22 761.3,-22 788.89,-3.47 843.48,-42 900.92,-82.54 929.61,-163.37 942.16,-211.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"938.69,-212.03 944.51,-220.89 945.49,-210.34 938.69,-212.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-175.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-160.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-145.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-130.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-115.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-100.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-85.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-70.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-55.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-40.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-25.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;hole -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.61,-329.6C168.36,-386.1 204.46,-513 291.61,-513 291.61,-513 291.61,-513 694.48,-513 819.64,-513 903.44,-358.18 935.67,-286.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"938.82,-287.65 939.62,-277.08 932.41,-284.84 938.82,-287.65\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-651.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-636.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-621.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-606.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-591.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-576.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-561.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-546.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-531.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-516.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"292.61\" cy=\"-303\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.61\" y=\"-306.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">C</text>\n",
       "<text text-anchor=\"middle\" x=\"292.61\" y=\"-291.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.83,-303C199.4,-303 230.36,-303 254.54,-303\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.28,-306.5 264.28,-303 254.28,-299.5 254.28,-306.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"221.74\" y=\"-321.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"221.74\" y=\"-306.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;1</text>\n",
       "</g>\n",
       "<!-- hole&#45;&gt;hole -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>hole&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M928.05,-266.13C916.66,-280.69 924.46,-296.28 951.48,-296.28 972.16,-296.28 981.59,-287.14 979.76,-276.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"983.01,-275.02 975.56,-267.5 976.69,-278.03 983.01,-275.02\"/>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-465.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-450.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-435.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-420.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-405.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-390.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-375.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-360.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-345.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-330.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-315.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"951.48\" y=\"-300.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;hole -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>C&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M319.3,-306.4C387.73,-314.83 579.91,-334.47 737.48,-312 801.05,-302.94 872.15,-279.38 914.02,-264.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"915.2,-267.35 923.35,-260.59 912.76,-260.79 915.2,-267.35\"/>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-475.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-460.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-445.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-430.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-415.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-400.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-385.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-370.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-355.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-340.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-325.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"487.48\" cy=\"-245\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-248.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D</text>\n",
       "<text text-anchor=\"middle\" x=\"487.48\" y=\"-233.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.43,-295.54C352.04,-285.43 412.25,-267.32 450.74,-255.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"451.43,-259.19 460,-252.96 449.42,-252.49 451.43,-259.19\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.48\" y=\"-291.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;1</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;hole -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>D&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M514.64,-245.28C592.01,-246.12 820,-248.59 911.67,-249.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"911.61,-253.08 921.65,-249.69 911.69,-246.08 911.61,-253.08\"/>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-296.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-281.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-266.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-251.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"693.48\" cy=\"-86\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-89.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">E</text>\n",
       "<text text-anchor=\"middle\" x=\"693.48\" y=\"-74.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;E -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>D&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M492.93,-218.52C499.58,-187.66 515.21,-137.51 549.48,-111 579.53,-87.76 623.77,-83.22 655.08,-83.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"654.79,-86.91 664.87,-83.66 654.96,-79.91 654.79,-86.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-219.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-204.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-189.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-174.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-159.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-129.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;1</text>\n",
       "<text text-anchor=\"middle\" x=\"590.48\" y=\"-114.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;1</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;hole -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>E&#45;&gt;hole</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M716.8,-72.41C747.43,-55.68 803.26,-32.25 843.48,-56 900.27,-89.53 928.99,-165.18 941.76,-211.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"938.37,-212.33 944.29,-221.11 945.14,-210.55 938.37,-212.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-224.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-209.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-194.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-164.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-149.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-134.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-119.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-104.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-89.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-74.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"799.48\" y=\"-59.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15a96733610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(guiding_wfa)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.syncronic_model_guided_language_model import SyncronicModelGuidedLanguageModel\n",
    "from mini_relm_resources.automata_examples.man_woman_wfa import get_man_woman_wfa\n",
    "\n",
    "property_model = get_man_woman_wfa(wrapper.terminal_symbol)\n",
    "\n",
    "syncrhronic_model = SyncronicModelGuidedLanguageModel(wrapper, property_model, model_name=\"GUIDED_GPT2\", max_seq_length=10, normalize_outputs=True, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymodelextractor.teachers.pac_probabilistic_teacher import PACProbabilisticTeacher\n",
    "from utilities.hypothesis_aware_sample_probabilistic_teacher import HypothesisAwareSampleProbabilisticTeacher\n",
    "from pymodelextractor.learners.observation_tree_learners.bounded_pdfa_quantization_n_ary_tree_learner import BoundedPDFAQuantizationNAryTreeLearner\n",
    "from pythautomata.utilities.probability_partitioner import TopKProbabilityPartitioner, QuantizationProbabilityPartitionerPlus, RankingPartitioner\n",
    "from pythautomata.model_comparators.wfa_partition_comparison_strategy import WFAPartitionComparator\n",
    "from pythautomata.utilities.uniform_word_sequence_generator import UniformWordSequenceGenerator\n",
    "partitioner = QuantizationProbabilityPartitionerPlus(100000)\n",
    "comparator = WFAPartitionComparator(partitioner)\n",
    "epsilon = 0.1\n",
    "delta = epsilon\n",
    "sequence_generator = guiding_generator\n",
    "max_states = 30\n",
    "max_query_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = HypothesisAwareSampleProbabilisticTeacher(syncrhronic_model, comparator, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teacher  = PACProbabilisticTeacher(syncrhronic_model, epsilon = epsilon, delta = delta, max_seq_length = None, comparator = comparator, sequence_generator=guiding_generator, compute_epsilon_star=False)\n",
    "learner = BoundedPDFAQuantizationNAryTreeLearner(partitioner, max_states, max_query_length, None, generate_partial_hipothesis = True, pre_cache_queries_for_building_hipothesis = True,  check_probabilistic_hipothesis = False, omit_zero_transitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before update: 6\n",
      "CE: The,woman,was trained in\n",
      "----update_node----\n",
      "Old Node (new Leaf) The,man\n",
      "New Leaf The,woman\n",
      "dict_keys([The, , The,man, The,man,was trained in, The,man,was trained in,engineering, The,woman,was trained in])\n",
      "dict_keys([The, , The,man, The,man,was trained in, The,man,was trained in,engineering, The,woman,was trained in, The,woman])\n",
      "--------\n",
      "Size after update: 8\n"
     ]
    }
   ],
   "source": [
    "learning_result = learner.learn(teacher, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: weighted_automaton Pages: 1 -->\n",
       "<svg width=\"1080pt\" height=\"702pt\"\n",
       " viewBox=\"0.00 0.00 1080.00 701.94\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.623395 0.623395) rotate(0) translate(4 1122)\">\n",
       "<title>weighted_automaton</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1122 1728.45,-1122 1728.45,4 -4,4\"/>\n",
       "<!-- HOLE -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>HOLE</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1634.45\" cy=\"-564\" rx=\"37.45\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-567.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">HOLE</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-552.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- HOLE&#45;&gt;HOLE -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>HOLE&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1607.41,-590.54C1602.13,-605.57 1611.15,-619.48 1634.45,-619.48 1651.75,-619.48 1661.17,-611.81 1662.72,-601.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1666.23,-601.6 1661.65,-592.05 1659.27,-602.37 1666.23,-601.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-788.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-773.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-758.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-743.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-728.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-713.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-698.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-683.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-668.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-653.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-638.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1634.45\" y=\"-623.28\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>The</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.87\" cy=\"-540\" rx=\"26.74\" ry=\"26.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.87\" y=\"-543.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The</text>\n",
       "<text text-anchor=\"middle\" x=\"174.87\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- The&#45;&gt;HOLE -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>The&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M180.42,-566.45C198.11,-659.76 271.32,-968 466.43,-968 466.43,-968 466.43,-968 1271.54,-968 1461.85,-968 1577.23,-716.22 1617.38,-610.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1620.63,-611.51 1620.84,-600.92 1614.07,-609.07 1620.63,-611.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1106.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1091.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1076.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1061.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1046.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1031.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1016.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-1001.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-986.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-971.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>The,man</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"467.43\" cy=\"-622\" rx=\"45.92\" ry=\"45.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"467.43\" y=\"-625.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man</text>\n",
       "<text text-anchor=\"middle\" x=\"467.43\" y=\"-610.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- The&#45;&gt;The,man -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>The&#45;&gt;The,man</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201.15,-547.13C247.91,-560.33 348.88,-588.82 411.88,-606.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"410.77,-609.93 421.34,-609.28 412.67,-603.19 410.77,-609.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"305.24\" y=\"-603.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0.8150600326411005</text>\n",
       "</g>\n",
       "<!-- The,woman -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>The,woman</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"467.43\" cy=\"-412\" rx=\"58.88\" ry=\"58.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"467.43\" y=\"-415.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,woman</text>\n",
       "<text text-anchor=\"middle\" x=\"467.43\" y=\"-400.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- The&#45;&gt;The,woman -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>The&#45;&gt;The,woman</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.65,-529.53C243.56,-510.18 338.71,-468.26 402.68,-440.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"403.93,-443.36 411.67,-436.12 401.11,-436.95 403.93,-443.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"305.24\" y=\"-521.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0.18493996735889956</text>\n",
       "</g>\n",
       "<!-- The,man&#45;&gt;HOLE -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>The,man&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M504.5,-649.55C541.58,-676.23 602.1,-715.31 661.12,-734 741.66,-759.51 1342.28,-806.05 1420.45,-774 1503.73,-739.85 1571.88,-655.68 1607.21,-604.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1610.02,-606.97 1612.78,-596.74 1604.24,-603.02 1610.02,-606.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-931.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-916.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-901.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-886.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-871.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-856.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-841.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-826.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-811.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-796.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-781.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man,was trained in -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>The,man,was trained in</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"776.38\" cy=\"-622\" rx=\"103.48\" ry=\"103.48\"/>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-625.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man,was trained in</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-610.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- The,man&#45;&gt;The,man,was trained in -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>The,man&#45;&gt;The,man,was trained in</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M513.72,-622C552.48,-622 609.97,-622 661.2,-622\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"661.19,-625.5 671.19,-622 661.19,-618.5 661.19,-625.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-625.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;1.0</text>\n",
       "</g>\n",
       "<!-- The,woman&#45;&gt;HOLE -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>The,woman&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M526.6,-411.48C611,-410.75 772.33,-409.47 909.64,-409 995.41,-408.71 1038.13,-352.46 1102.64,-409 1148.49,-449.19 1075.53,-503.97 1120.64,-545 1154.48,-575.79 1464.17,-569.4 1585.25,-565.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1585.3,-569.17 1595.19,-565.36 1585.08,-562.18 1585.3,-569.17\"/>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-562.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-547.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-532.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-517.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-502.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-487.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-472.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-457.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-442.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-427.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-412.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,woman,was trained in -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>The,woman,was trained in</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"776.38\" cy=\"-269\" rx=\"115.02\" ry=\"115.02\"/>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-272.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,woman,was trained in</text>\n",
       "<text text-anchor=\"middle\" x=\"776.38\" y=\"-257.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- The,woman&#45;&gt;The,woman,was trained in -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>The,woman&#45;&gt;The,woman,was trained in</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M521.2,-387.42C559.68,-369.49 613.3,-344.51 661.37,-322.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"662.58,-325.41 670.16,-318.02 659.62,-319.07 662.58,-325.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-376.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;1.0</text>\n",
       "</g>\n",
       "<!-- The,man,was trained in&#45;&gt;HOLE -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>The,man,was trained in&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.87,-629.66C889.93,-630.21 899.98,-630.67 909.64,-631 995.36,-633.91 1018.33,-646.82 1102.64,-631 1111.07,-629.42 1112.3,-626.06 1120.64,-624 1296.87,-580.52 1346.27,-600 1526.45,-578 1545.76,-575.64 1567.02,-572.89 1585.46,-570.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1585.87,-573.93 1595.32,-569.15 1584.95,-567 1585.87,-573.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-762.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-747.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-732.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-717.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-702.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-687.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-672.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-657.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-642.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-627.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,man,was trained in,engineering -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>The,man,was trained in,engineering</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1270.54\" cy=\"-386\" rx=\"149.81\" ry=\"149.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-389.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The,man,was trained in,engineering</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-374.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.0</text>\n",
       "</g>\n",
       "<!-- The,man,was trained in&#45;&gt;The,man,was trained in,engineering -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>The,man,was trained in&#45;&gt;The,man,was trained in,engineering</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M878.77,-605.49C889.19,-603.92 899.62,-602.39 909.64,-601 995.2,-589.11 1026.29,-618.42 1102.64,-578 1130.57,-563.21 1155.93,-541.69 1177.97,-518.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1180.41,-520.87 1184.6,-511.14 1175.26,-516.13 1180.41,-520.87\"/>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-619.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0.427116700866265</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-604.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0.572883299133735</text>\n",
       "</g>\n",
       "<!-- The,man,was trained in,engineering&#45;&gt;HOLE -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>The,man,was trained in,engineering&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1416.04,-348.55C1454.07,-346.05 1493.61,-350.61 1526.45,-370 1579.69,-401.44 1608.26,-469.88 1622.15,-516.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1618.77,-517.4 1624.87,-526.06 1625.5,-515.48 1618.77,-517.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-538.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-523.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-508.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-493.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-478.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-463.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-448.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-433.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-418.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-403.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-388.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1482.45\" y=\"-373.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,woman,was trained in&#45;&gt;HOLE -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>The,woman,was trained in&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M869.03,-200.59C935.15,-155.68 1028.63,-100.98 1120.64,-77 1185.11,-60.19 1364.69,-40.53 1420.45,-77 1573.08,-176.83 1616.99,-412.77 1629.08,-515.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1625.58,-515.34 1630.18,-524.89 1632.54,-514.56 1625.58,-515.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-185.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-170.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-155.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-140.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-125.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-110.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-95.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"1270.54\" y=\"-80.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- The,woman,was trained in&#45;&gt;The,man,was trained in,engineering -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>The,woman,was trained in&#45;&gt;The,man,was trained in,engineering</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M888.75,-295.48C955.1,-311.25 1040.34,-331.51 1113.34,-348.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1112.47,-352.26 1123.01,-351.17 1114.09,-345.45 1112.47,-352.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-362.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0.27878876998968977</text>\n",
       "<text text-anchor=\"middle\" x=\"1006.14\" y=\"-347.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0.7212112300103103</text>\n",
       "</g>\n",
       "<!--  -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-76 0,-38 34,0 68,-38 34,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-41.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"></text>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-26.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;HOLE -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>&#45;&gt;HOLE</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.88,-32.72C91.89,-28.06 135.65,-22 173.87,-22 173.87,-22 173.87,-22 1271.54,-22 1388.35,-22 1447.66,0.23 1526.45,-86 1583.94,-148.92 1617,-406.36 1628.64,-515.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1625.14,-515.33 1629.67,-524.9 1632.11,-514.59 1625.14,-515.33\"/>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-175.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">art&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-160.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrology&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-145.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">astrophysics&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-130.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">engineering&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-115.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">man&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-100.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">maths&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-85.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">medicine&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-70.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">music&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-55.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">science&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-40.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">was trained in&#45;0</text>\n",
       "<text text-anchor=\"middle\" x=\"593.62\" y=\"-25.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">woman&#45;0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;The -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>&#45;&gt;The</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.86,-66.43C66.57,-152.13 137.34,-407.94 163.77,-503.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"160.32,-504.15 166.36,-512.85 167.07,-502.28 160.32,-504.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"108\" y=\"-380.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">The&#45;1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15a96a38fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pythautomata.model_exporters.dot_exporters.wfa_dot_exporting_strategy import WFADotExportingStrategy\n",
    "from IPython.display import display\n",
    "\n",
    "exporter = WFADotExportingStrategy()\n",
    "graph = exporter.create_graph(learning_result.model)\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfa = learning_result.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.utilities.pdfa_operations import get_representative_sample\n",
    "sample = get_representative_sample(pdfa, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythautomata.base_types.sequence import Sequence\n",
    "from pythautomata.base_types.symbol import SymbolStr\n",
    "test_seq = Sequence([SymbolStr(\"The\"),SymbolStr(\"man\"),SymbolStr(\"studied\"), SymbolStr(\"music\")])\n",
    "#teacher.next_token_probabilities(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import OrderedDict\n",
    "#def next_token_probabilities(model, sequence):\n",
    "#        symbols = list(model.alphabet.symbols)\n",
    "#        symbols.sort()\n",
    "#        symbols = [model.terminal_symbol] + symbols\n",
    "#        probabilities = model.get_last_token_weights(sequence, symbols)\n",
    "#        probabilities = OrderedDict(zip(symbols, probabilities))\n",
    "#        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pythautomata.utilities.uniform_length_sequence_generator import UniformLengthSequenceGenerator\n",
    "#generator = UniformLengthSequenceGenerator(alphabet, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#res = list()\n",
    "#words = generator.generate_all_words()\n",
    "#for word in words:\n",
    "#    probs = list(next_token_probabilities(syncrhronic_model, word).values())\n",
    "#    if np.sum(probs) > 0:\n",
    "#        print(word, probs)\n",
    "#        res.append((word, probs))\n",
    "#    if len(res)>1000:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pythautomata.base_types.sequence import Sequence\n",
    "#from pythautomata.base_types.symbol import SymbolStr\n",
    "#the_man_studied = Sequence([SymbolStr(\"The\"),SymbolStr(\"man\"),SymbolStr(\"studied\")])\n",
    "#the_woman_studied = Sequence([SymbolStr(\"The\"),SymbolStr(\"woman\"),SymbolStr(\"studied\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#man = next_token_probabilities(syncrhronic_model, the_man_studied).values()\n",
    "#woman = next_token_probabilities(syncrhronic_model, the_woman_studied).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_token_probabilities(syncrhronic_model, the_woman_studied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper_res = next_token_probabilities(wrapper, the_woman_studied).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partitioner.get_partition(woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partitioner.get_partition(man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partitioner.are_in_same_partition(wrapper_res, woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partitioner.are_in_same_partition(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_token_probabilities(wrapper, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_token_probabilities(guiding_wfa, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_token_probabilities(syncrhronic_model, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymodelextractor_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
